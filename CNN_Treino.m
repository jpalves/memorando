%% Train a Convolutional Neural Network Using Data in ImageDatastore 
close all
clear
%% 
% Load the data as an |ImageDatastore| object.
digitDatasetPath = fullfile(matlabroot,'toolbox','nnet','nndemos',...
    'nndatasets','DigitDataset');
digitData = imageDatastore(digitDatasetPath,...
        'IncludeSubfolders',true,'LabelSource','foldernames');

%%
% The data store contains 10000 synthetic images of digits 0-9. The images
% are generated by applying random transformations to digit images created
% using different fonts. Each digit image is 28-by-28 pixels.

%% 
% Display some of the images in the datastore. 
figure;
perm = randperm(10000,20);
for i = 1:20
    subplot(4,5,i);
    imshow(digitData.Files{perm(i)});
end

%% 
% Check the number of images in each digit category. 
digitData.countEachLabel 

%%
% The data contains an equal number of images per category.  

%% 
% Divide the data set so that each category in the training set has 750 images
% and the testing set has the remaining images from each label. 
trainingNumFiles = 750;
rng(1) % For reproducibility
[trainDigitData,testDigitData] = splitEachLabel(digitData,...
				trainingNumFiles,'randomize'); 

%%
% |splitEachLabel| splits the image files in |digitData| into two new datastores,
% |trainDigitData| and |testDigitData|.  

%% 
% Define the convolutional neural network architecture. 
%layers = [imageInputLayer([28 28 1]);
%          convolution2dLayer(5,20);
%          reluLayer();
%          maxPooling2dLayer(2,'Stride',2);
%          fullyConnectedLayer(10);
%          softmaxLayer();
%          classificationLayer()];  

layers = [ ...
    imageInputLayer([28 28 1],'Name','input');
    convolution2dLayer(5,20,'Padding',1)
    crossChannelNormalizationLayer(3)
    reluLayer
    maxPooling2dLayer(2,'Stride',2);
    fullyConnectedLayer(10)
    softmaxLayer();
    classificationLayer;
]
    


%layers = [
%    imageInputLayer([28 28 1])  
%    convolution2dLayer(3,16,'Padding',1)
%    batchNormalizationLayer
%    reluLayer    
%    maxPooling2dLayer(2,'Stride',2) 
%    convolution2dLayer(3,32,'Padding',1)
%    batchNormalizationLayer
%    reluLayer 
%    fullyConnectedLayer(10)
%    softmaxLayer
%    classificationLayer];
%a = alexnet
%%
%inputSize = a.Layers(1).InputSize(1:2) 
%auimds = augmentedImageDatastore(inputSize,...,'OutputSizeMode','centercrop');

%im = imresize(im3d,inputSize);
%a.Layers(1) =  imageInputLayer([28 28 1],'Name','input');

%inputSize = a.Layers(1).InputSize(1:2) 


%% 
% Set the options to default settings for the stochastic gradient descent
% with momentum. Set the maximum number of epochs at 20, and start the
% training with an initial learning rate of 0.001.
options = trainingOptions('sgdm','MaxEpochs',20,...
	'InitialLearnRate',0.0001);  

%% 
% Train the network. 
convnet = trainNetwork(trainDigitData,layers,options);
%delete(gcp('nocreate'))
%% 
% Run the trained network on the test set that was not used to train the
% network and predict the image labels (digits).
YTest = classify(convnet,testDigitData);
TTest = testDigitData.Labels;

%% 
% Calculate the accuracy. 
accuracy = sum(YTest == TTest)/numel(TTest)   

%%
% Accuracy is the ratio of the number of true labels in the test data
% matching the classifications from classify, to the number of images in
% the test data. In this case about 98.5% of the digit estimations match the
% true digit values in the test set.
  
classify(convnet,imageDatastore(testDigitData.Files{1000}))
figure();
imshow(testDigitData.Files{1000})
